{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To help with reading and manipulating data\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# To help with data visualization\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# To be used for missing value imputation\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "# To help with model building\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import (\n",
    "    AdaBoostClassifier,\n",
    "    GradientBoostingClassifier,\n",
    "    RandomForestClassifier,\n",
    "    BaggingClassifier,\n",
    ")\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "# To get different metric scores, and split data\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold, cross_val_score\n",
    "from sklearn.metrics import (\n",
    "    f1_score,\n",
    "    accuracy_score,\n",
    "    recall_score,\n",
    "    precision_score,\n",
    "    confusion_matrix,\n",
    "    roc_auc_score,\n",
    "    plot_confusion_matrix,\n",
    ")\n",
    "\n",
    "# To be used for data scaling and one hot encoding\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler, OneHotEncoder\n",
    "\n",
    "# To be used for tuning the model\n",
    "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV\n",
    "\n",
    "# To be used for creating pipelines and personalizing them\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "# To define maximum number of columns to be displayed in a dataframe\n",
    "pd.set_option(\"display.max_columns\", None)\n",
    "\n",
    "# To supress scientific notations for a dataframe\n",
    "pd.set_option(\"display.float_format\", lambda x: \"%.3f\" % x)\n",
    "\n",
    "# To supress warnings\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# This will help in making the Python code more structured automatically (good coding practice)\n",
    "%load_ext nb_black"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Description\n",
    "Background & Context\n",
    "\n",
    "The Thera bank recently saw a steep decline in the number of users of their credit card, credit cards are a good source of income for banks because of different kinds of fees charged by the banks like annual fees, balance transfer fees, and cash advance fees, late payment fees, foreign transaction fees, and others. Some fees are charged to every user irrespective of usage, while others are charged under specified circumstances.\n",
    "\n",
    "Customers’ leaving credit cards services would lead bank to loss, so the bank wants to analyze the data of customers and identify the customers who will leave their credit card services and reason for same – so that bank could improve upon those areas\n",
    "\n",
    "You as a Data scientist at Thera bank need to come up with a classification model that will help the bank improve its services so that customers do not renounce their credit cards\n",
    "\n",
    "You need to identify the best possible model that will give the required performance\n",
    "\n",
    "Objective\n",
    "\n",
    "Explore and visualize the dataset.\n",
    "Build a classification model to predict if the customer is going to churn or not\n",
    "Optimize the model using appropriate techniques\n",
    "Generate a set of insights and recommendations that will help the bank\n",
    "Data Dictionary:\n",
    "\n",
    "CLIENTNUM: Client number. Unique identifier for the customer holding the account\n",
    "Attrition_Flag: Internal event (customer activity) variable - if the account is closed then \"Attrited Customer\" else \"Existing Customer\"\n",
    "Customer_Age: Age in Years\n",
    "Gender: Gender of the account holder\n",
    "Dependent_count: Number of dependents\n",
    "Education_Level:  Educational Qualification of the account holder - Graduate, High School, Unknown, Uneducated, College(refers to a college student), Post-Graduate, Doctorate.\n",
    "Marital_Status: Marital Status of the account holder\n",
    "Income_Category: Annual Income Category of the account holder\n",
    "Card_Category: Type of Card\n",
    "Months_on_book: Period of relationship with the bank\n",
    "Total_Relationship_Count: Total no. of products held by the customer\n",
    "Months_Inactive_12_mon: No. of months inactive in the last 12 months\n",
    "Contacts_Count_12_mon: No. of Contacts between the customer and bank in the last 12 months\n",
    "Credit_Limit: Credit Limit on the Credit Card\n",
    "Total_Revolving_Bal: The balance that carries over from one month to the next is the revolving balance\n",
    "Avg_Open_To_Buy: Open to Buy refers to the amount left on the credit card to use (Average of last 12 months)\n",
    "Total_Trans_Amt: Total Transaction Amount (Last 12 months)\n",
    "Total_Trans_Ct: Total Transaction Count (Last 12 months)\n",
    "Total_Ct_Chng_Q4_Q1: Ratio of the total transaction count in 4th quarter and the total transaction count in 1st quarter\n",
    "Total_Amt_Chng_Q4_Q1: Ratio of the total transaction amount in 4th quarter and the total transaction amount in 1st quarter\n",
    "Avg_Utilization_Ratio: Represents how much of the available credit the customer spent\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('BankChurners.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Dependant Variable = Attrition_Flag\n",
    "* It looks like the Income_Category attribute has some data 'abc' that does not fit will look at it furthere down\n",
    "* Can drop clientnum as it wont be relevant to build this model but will be in use of the model later. \n",
    "* Generate One Hots\n",
    "    - Attrition_Flag\n",
    "    - Gender\n",
    "    - Education_Level\n",
    "    - Married_Status\n",
    "    - Income_Category\n",
    "    - Card_Category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(columns='CLIENTNUM')\n",
    "one_hots = ['Attrition_Flag','Gender','Education_Level','Marital_Status','Income_Category', 'Card_Category']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe().T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generating a data frame of missing values by count and %\n",
    "missing = (df.isnull().sum()/df.isnull().count()*100).sort_values(ascending=False)\n",
    "missing = pd.DataFrame(missing, columns=['%'])\n",
    "missing['count'] = df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Missing Values in the data frame')\n",
    "missing.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are a large number of missing values in:\n",
    "     - Education_Level\n",
    "     - Martial_Status\n",
    "\n",
    "Will have to look into these attributues in addition to the Income_Category to see if we can impute the data or need to drop those rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('The count of unique values in the data frame')\n",
    "df.nunique().sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Printing a list of unique values, values shown in text file. Some categories have a large number of values so dropping those\n",
    "\n",
    "vc = df.columns.drop(['Avg_Open_To_Buy','Credit_Limit','Total_Revolving_Bal','Total_Amt_Chng_Q4_Q1', 'Avg_Utilization_Ratio','Total_Ct_Chng_Q4_Q1','Total_Trans_Ct','Customer_Age','Months_on_book',])\n",
    "for i in vc:\n",
    "    print(i,'Has the following Unique Values')\n",
    "    print(df[i].value_counts().sort_values(ascending=False))\n",
    "    print('-'*50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Initial observations\n",
    "* CLEINTNUM is not needed for this model we can use the index and drop this column\n",
    "* Attrition_Flag is our dependant variable\n",
    "<br/><br/>\n",
    "\n",
    "* The following columns have missing values or other issues we will need to fix\n",
    "   - Education_Level - has a number of missing values, will drop those as there is no hard data to fill in\n",
    "   - Marital_Status - has a number of missing values, will drop those as there is no hard data to fill in\n",
    "   - Income_Category - has a category 'abc', those rows might need to be dropped if no correlations can be found to impute the data. \n",
    "   <br/><br/>\n",
    "\n",
    "* The following categorical columns can be dummies\n",
    "   - Attrition_Flag\n",
    "   - Gender\n",
    "   - Education_Level\n",
    "   - Married_Status\n",
    "   - Income_Category\n",
    "   - Card_Category\n",
    "   <br/><br/>\n",
    "\n",
    "* Customer Observation:\n",
    "   -  Customers range in age from mid 20s to early 70s. The average customer age is mid 40s\n",
    "   -  Customers have an average of 2.3 dependants\n",
    "   -  On average customers have been with the bank for right at 3 years, with the longest being 56 months. This is a newer bank\n",
    "   -  The min age for a customer is 13 months, this means the bank has not signed any new customers in over a year.\n",
    "   - The typical customer has 3-4 products from the bank\n",
    "   - Most inactive customers have been so for just over 2 months, it would appear inactive accounts are closed after 12 months\n",
    "   - The bank attempts to contact a customer 2-3 times a year\n",
    "   - The average credit limit 8600 with the max being 34,500\n",
    "   - The typical customer carries over a roughly 1200 balance month to month  \n",
    "   - Most customers use less than 25% of their available credit    \n",
    "   <br/><br/>\n",
    "\n",
    "* Attributes with Possible Outliers:\n",
    "   - Credit_Limit - has a high end roughly 3 times that of the 75% quartile. While this is most likely an outlier I do not know it is bad for the model. Will dig more into this.\n",
    "   - Avg_Utilization_Ratio - has a max almost double the 75%. That being said this might skew the model but is data that is important to identifying customer trends.\n",
    "   - Customer_Age - Has outliers but considering the nature of the attribute will not treat\n",
    "   - Months_on_Book - Has outliers but considering the nature of the attribute will not treat\n",
    "   - Credit_Limit - Has outliers but considering the nature of the attribute will not treat\n",
    "   - Total_Trans_Amt - Has outliers but considering the nature of the attribute will not treat\n",
    "   <br/><br/>\n",
    "\n",
    "* General Observations:\n",
    "   - The income category has a value of ‘abc’ that will need treatment\n",
    "   <br/><br/>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fixing Education_Level, Marital_Status & Income_Categories  \n",
    "\n",
    "- Dropping missing values  \n",
    "- Evaluating if there is a way to impute Income_Categories from the data available"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dropping rows with missing values\n",
    "df.dropna(inplace=True)\n",
    "\n",
    "# Confirming all missing values have been treated\n",
    "df.isnull().sum().sort_index(ascending=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lets look at Income Category\n",
    "df['Income_Category'].value_counts().sort_values(ascending=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a dataframe for rows with 'abc' for Income_Category to look at the data\n",
    "abc = df.loc[df['Income_Category'] == 'abc']\n",
    "abc.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is not a good correlation to impute a usable value instead of 'abc' will drop all rows with that value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[df['Income_Category'] != 'abc']\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Between missing value treatments and the bad data for income we have cut out about 30% of our data set. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EDA  \n",
    "-------------------------------\n",
    "#### Reusable Functions\n",
    "- Reusing functions provided in the class  \n",
    "- Functions for both Univariate and Bivariate Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reusing provided function for generating graphs\n",
    "\n",
    "def histogram_boxplot(data, feature, figsize=(12, 7), kde=False, bins=None):\n",
    "    \"\"\"\n",
    "    Boxplot and histogram combined\n",
    "\n",
    "    data: dataframe\n",
    "    feature: dataframe column\n",
    "    figsize: size of figure (default (12,7))\n",
    "    kde: whether to show the density curve (default False)\n",
    "    bins: number of bins for histogram (default None)\n",
    "    \"\"\"\n",
    "    f2, (ax_box2, ax_hist2) = plt.subplots(\n",
    "        nrows=2,  # Number of rows of the subplot grid= 2\n",
    "        sharex=True,  # x-axis will be shared among all subplots\n",
    "        gridspec_kw={\"height_ratios\": (0.25, 0.75)},\n",
    "        figsize=figsize,\n",
    "    )  # creating the 2 subplots\n",
    "    \n",
    "    sns.boxplot(\n",
    "        data=data, x=feature, ax=ax_box2, showmeans=True, color=\"violet\"\n",
    "    )  # boxplot will be created and a star will indicate the mean value of the column\n",
    "    sns.histplot(\n",
    "        data=data, x=feature, kde=kde, ax=ax_hist2, bins=bins, palette=\"winter\"\n",
    "    ) if bins else sns.histplot(\n",
    "        data=data, x=feature, kde=kde, ax=ax_hist2\n",
    "    )  # For histogram\n",
    "    ax_hist2.axvline(\n",
    "        data[feature].mean(), color=\"green\", linestyle=\"--\"\n",
    "    )  # Add mean to the histogram\n",
    "    ax_hist2.axvline(\n",
    "        data[feature].median(), color=\"black\", linestyle=\"-\"\n",
    "    )  # Add median to the histogram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reusing provided function for generating graphs\n",
    "# function to create labeled barplots\n",
    "\n",
    "\n",
    "def labeled_barplot(data, feature, perc=False, n=None):\n",
    "    \"\"\"\n",
    "    Barplot with percentage at the top\n",
    "\n",
    "    data: dataframe\n",
    "    feature: dataframe column\n",
    "    perc: whether to display percentages instead of count (default is False)\n",
    "    n: displays the top n category levels (default is None, i.e., display all levels)\n",
    "    \"\"\"\n",
    "\n",
    "    total = len(data[feature])  # length of the column\n",
    "    count = data[feature].nunique()\n",
    "    if n is None:\n",
    "        plt.figure(figsize=(count + 1, 5))\n",
    "    else:\n",
    "        plt.figure(figsize=(n + 1, 5))\n",
    "\n",
    "    plt.xticks(rotation=90, fontsize=15)\n",
    "    ax = sns.countplot(\n",
    "        data=data,\n",
    "        x=feature,\n",
    "        palette=\"Paired\",\n",
    "        order=data[feature].value_counts().index[:n].sort_values(),\n",
    "    )\n",
    "\n",
    "    for p in ax.patches:\n",
    "        if perc == True:\n",
    "            label = \"{:.1f}%\".format(\n",
    "                100 * p.get_height() / total\n",
    "            )  # percentage of each class of the category\n",
    "        else:\n",
    "            label = p.get_height()  # count of each level of the category\n",
    "\n",
    "        x = p.get_x() + p.get_width() / 2  # width of the plot\n",
    "        y = p.get_height()  # height of the plot\n",
    "\n",
    "        ax.annotate(\n",
    "            label,\n",
    "            (x, y),\n",
    "            ha=\"center\",\n",
    "            va=\"center\",\n",
    "            size=12,\n",
    "            xytext=(0, 5),\n",
    "            textcoords=\"offset points\",\n",
    "        )  # annotate the percentage\n",
    "\n",
    "    plt.show()  # show the plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reusing provided function for generating graphs\n",
    "\n",
    "def stacked_barplot(data, predictor, target):\n",
    "    \"\"\"\n",
    "    Print the category counts and plot a stacked bar chart\n",
    "    data: dataframe\n",
    "    predictor: independent variable\n",
    "    target: target variable\n",
    "    \"\"\"\n",
    "    count = data[predictor].nunique()\n",
    "    sorter = data[target].value_counts().index[-1]\n",
    "    tab1 = pd.crosstab(data[predictor], data[target], margins=True).sort_values(\n",
    "        by=sorter, ascending=False\n",
    "    )\n",
    "    print(tab1)\n",
    "    print(\"-\" * 120)\n",
    "    tab = pd.crosstab(data[predictor], data[target], normalize=\"index\").sort_values(\n",
    "        by=sorter, ascending=False\n",
    "    )\n",
    "    tab.plot(kind=\"bar\", stacked=True, figsize=(count + 5, 5))\n",
    "    plt.legend(\n",
    "        loc=\"lower left\", frameon=False,\n",
    "    )\n",
    "    plt.legend(loc=\"upper left\", bbox_to_anchor=(1, 1))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating histograms\n",
    "df.hist(figsize=(14, 14))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "histogram_boxplot(df, 'Avg_Utilization_Ratio')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "histogram_boxplot(df, 'Customer_Age')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "histogram_boxplot(df, 'Dependent_count')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "histogram_boxplot(df, 'Months_on_book')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "histogram_boxplot(df, 'Total_Relationship_Count')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "histogram_boxplot(df, 'Credit_Limit')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "histogram_boxplot(df, 'Total_Trans_Amt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "histogram_boxplot(df, 'Total_Trans_Ct')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot = ['Gender', 'Dependent_count', 'Education_Level', 'Marital_Status', 'Income_Category', 'Total_Relationship_Count', 'Total_Trans_Ct']\n",
    "plot = ['Dependent_Count']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in plot:\n",
    "    labeled_barplot(plot, i, perc=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.8 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "f3f87633aac09da3bda522f97956bee375b5501d1579e6458804e567301cb62a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
